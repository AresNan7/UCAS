# PyTorch å¤šæ–‡ä»¶é¡¹ç›®ç¤ºä¾‹

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ PyTorch å¤šæ–‡ä»¶é¡¹ç›®ç¤ºä¾‹ï¼ŒåŒ…å«å¤šç§å¸¸ç”¨æ¨¡å‹å’Œè®­ç»ƒå·¥å…·ï¼Œé€‚åˆåœ¨ Google Colab ä¸Šè¿›è¡Œå¤šæ–‡ä»¶æµ‹è¯•ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
UCAS/
â”œâ”€â”€ models/                  # æ¨¡å‹ç›®å½•
â”‚   â”œâ”€â”€ __init__.py         # æ¨¡å‹åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ simple_nn.py        # ç®€å•ç¥ç»ç½‘ç»œï¼ˆMLPï¼‰
â”‚   â”œâ”€â”€ cnn.py              # å·ç§¯ç¥ç»ç½‘ç»œ
â”‚   â”œâ”€â”€ resnet.py           # ResNet æ®‹å·®ç½‘ç»œ
â”‚   â””â”€â”€ lstm.py             # LSTM å¾ªç¯ç¥ç»ç½‘ç»œ
â”œâ”€â”€ utils/                   # å·¥å…·ç›®å½•
â”‚   â”œâ”€â”€ __init__.py         # å·¥å…·åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ data_loader.py      # æ•°æ®åŠ è½½å·¥å…·
â”‚   â””â”€â”€ train_utils.py      # è®­ç»ƒå·¥å…·å‡½æ•°
â”œâ”€â”€ train.py                 # è®­ç»ƒä¸»è„šæœ¬
â”œâ”€â”€ colab_demo.ipynb        # Colab æ¼”ç¤º Notebook
â”œâ”€â”€ requirements.txt        # ä¾èµ–åŒ…åˆ—è¡¨
â””â”€â”€ README_PYTORCH.md       # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æœ¬åœ°ä½¿ç”¨

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œè®­ç»ƒè„šæœ¬
python train.py --model simple_nn  # è®­ç»ƒç®€å•ç¥ç»ç½‘ç»œ
python train.py --model cnn        # è®­ç»ƒ CNN
python train.py --model resnet     # è®­ç»ƒ ResNet
python train.py --model lstm       # è®­ç»ƒ LSTM
python train.py --model all        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
```

### 2. åœ¨ Google Colab ä¸­ä½¿ç”¨

#### æ–¹æ³• A: ä» GitHub å…‹éš†

```python
# åœ¨ Colab å•å…ƒæ ¼ä¸­è¿è¡Œ
!git clone https://github.com/your-username/UCAS.git
%cd UCAS
!pip install -r requirements.txt
```

#### æ–¹æ³• B: æ‰‹åŠ¨ä¸Šä¼ æ–‡ä»¶

1. å°†æ•´ä¸ªé¡¹ç›®æ–‡ä»¶å¤¹å‹ç¼©ä¸º ZIP
2. åœ¨ Colab ä¸­è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

```python
from google.colab import files
uploaded = files.upload()  # ä¸Šä¼  ZIP æ–‡ä»¶

!unzip UCAS.zip
%cd UCAS
!pip install -r requirements.txt
```

#### æ–¹æ³• C: ä½¿ç”¨ Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')
%cd /content/drive/MyDrive/UCAS
!pip install -r requirements.txt
```

### 3. ä½¿ç”¨ Jupyter Notebook

æ‰“å¼€ `colab_demo.ipynb` æ–‡ä»¶ï¼ŒæŒ‰ç…§æ­¥éª¤æ‰§è¡Œå³å¯ã€‚

## ğŸ“š æ¨¡å‹ä»‹ç»

### 1. SimpleNN (`models/simple_nn.py`)

ç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œé€‚ç”¨äºï¼š
- MNIST æ‰‹å†™æ•°å­—è¯†åˆ«
- ç®€å•çš„åˆ†ç±»ä»»åŠ¡
- å­¦ä¹ åŸºç¡€çš„ç¥ç»ç½‘ç»œæ¦‚å¿µ

**ç‰¹ç‚¹**ï¼š
- å¯é…ç½®çš„éšè—å±‚æ•°é‡å’Œå¤§å°
- Batch Normalization
- Dropout æ­£åˆ™åŒ–

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from models import SimpleNN

model = SimpleNN(
    input_size=784,
    hidden_sizes=[512, 256, 128],
    num_classes=10,
    dropout=0.5
)
```

### 2. SimpleCNN & AdvancedCNN (`models/cnn.py`)

å·ç§¯ç¥ç»ç½‘ç»œï¼Œé€‚ç”¨äºï¼š
- å›¾åƒåˆ†ç±»ï¼ˆCIFAR-10, CIFAR-100ï¼‰
- ç‰¹å¾æå–
- è®¡ç®—æœºè§†è§‰ä»»åŠ¡

**ç‰¹ç‚¹**ï¼š
- SimpleCNNï¼šåŸºç¡€ CNN æ¶æ„
- AdvancedCNNï¼šæ·±å±‚ç½‘ç»œ + Batch Normalization

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from models import SimpleCNN, AdvancedCNN

# ç®€å• CNN
model = SimpleCNN(num_classes=10, in_channels=3)

# é«˜çº§ CNN
model = AdvancedCNN(num_classes=10, in_channels=3)
```

### 3. ResNet (`models/resnet.py`)

æ®‹å·®ç½‘ç»œï¼Œé€‚ç”¨äºï¼š
- æ·±åº¦å›¾åƒåˆ†ç±»
- è¿ç§»å­¦ä¹ 
- ç‰¹å¾æå–

**ç‰¹ç‚¹**ï¼š
- ResNet-18 å’Œ ResNet-34 ä¸¤ç§é…ç½®
- æ®‹å·®è¿æ¥è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
- é€‚åº”æ€§å¼º

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from models import ResNet18, ResNet34

# ResNet-18
model = ResNet18(num_classes=10, in_channels=3)

# ResNet-34
model = ResNet34(num_classes=10, in_channels=3)
```

### 4. SimpleLSTM & BidirectionalLSTM (`models/lstm.py`)

å¾ªç¯ç¥ç»ç½‘ç»œï¼Œé€‚ç”¨äºï¼š
- æ–‡æœ¬åˆ†ç±»
- åºåˆ—é¢„æµ‹
- æ—¶é—´åºåˆ—åˆ†æ

**ç‰¹ç‚¹**ï¼š
- SimpleLSTMï¼šå•å‘ LSTM
- BidirectionalLSTMï¼šåŒå‘ LSTM + æ³¨æ„åŠ›æœºåˆ¶

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from models import SimpleLSTM, BidirectionalLSTM

# ç®€å• LSTM
model = SimpleLSTM(
    vocab_size=10000,
    embedding_dim=128,
    hidden_dim=256,
    num_classes=5
)

# åŒå‘ LSTM
model = BidirectionalLSTM(
    vocab_size=10000,
    embedding_dim=128,
    hidden_dim=256,
    num_classes=5
)
```

## ğŸ› ï¸ å·¥å…·å‡½æ•°

### æ•°æ®åŠ è½½ (`utils/data_loader.py`)

æä¾›å¸¸ç”¨æ•°æ®é›†çš„åŠ è½½å‡½æ•°ï¼š

```python
from utils import get_mnist_loaders, get_cifar10_loaders, create_synthetic_dataset

# MNIST
train_loader, test_loader = get_mnist_loaders(batch_size=64)

# CIFAR-10
train_loader, test_loader = get_cifar10_loaders(batch_size=128, augment=True)

# åˆæˆæ•°æ®ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
train_loader, test_loader = create_synthetic_dataset(num_samples=1000)
```

### è®­ç»ƒå·¥å…· (`utils/train_utils.py`)

æä¾›å®Œæ•´çš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æµç¨‹ï¼š

```python
from utils import train_epoch, validate, test, save_checkpoint, load_checkpoint
from utils import EarlyStopping, MetricTracker

# è®­ç»ƒä¸€ä¸ª epoch
train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)

# éªŒè¯
val_loss, val_acc = validate(model, val_loader, criterion, device)

# æµ‹è¯•
test_acc, predictions, labels = test(model, test_loader, device)

# ä¿å­˜æ¨¡å‹
save_checkpoint(model, optimizer, epoch, loss, acc, 'checkpoint.pth')

# åŠ è½½æ¨¡å‹
epoch, loss, acc = load_checkpoint(model, optimizer, 'checkpoint.pth', device)

# æ—©åœæœºåˆ¶
early_stopping = EarlyStopping(patience=5)
early_stopping(val_loss)

# æŒ‡æ ‡è¿½è¸ª
tracker = MetricTracker()
tracker.update(train_loss, train_acc, val_loss, val_acc)
tracker.print_summary()
```

## ğŸ“Š å®Œæ•´è®­ç»ƒç¤ºä¾‹

```python
import torch
import torch.nn as nn
import torch.optim as optim
from models import ResNet18
from utils import get_cifar10_loaders, train_epoch, validate, MetricTracker

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# åŠ è½½æ•°æ®
train_loader, test_loader = get_cifar10_loaders(batch_size=128)

# åˆ›å»ºæ¨¡å‹
model = ResNet18(num_classes=10).to(device)

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)

# è®­ç»ƒ
num_epochs = 100
tracker = MetricTracker()

for epoch in range(num_epochs):
    print(f"Epoch {epoch + 1}/{num_epochs}")
    
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
    val_loss, val_acc = validate(model, test_loader, criterion, device)
    
    tracker.update(train_loss, train_acc, val_loss, val_acc)
    scheduler.step()
    
    print(f"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
    print(f"Val - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")

# æ‰“å°æ€»ç»“
tracker.print_summary()
```

## ğŸ’¡ Colab ä½¿ç”¨æŠ€å·§

### 1. æ£€æŸ¥ GPU

```python
import torch
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU å‹å·: {torch.cuda.get_device_name(0)}")
    print(f"GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

### 2. æŒ‚è½½ Google Driveï¼ˆä¿å­˜æ¨¡å‹ï¼‰

```python
from google.colab import drive
drive.mount('/content/drive')

# ä¿å­˜åˆ° Drive
save_checkpoint(model, optimizer, epoch, loss, acc, 
                '/content/drive/MyDrive/models/checkpoint.pth')
```

### 3. ç›‘æ§è®­ç»ƒè¿›åº¦

```python
# ä½¿ç”¨ TensorBoard
%load_ext tensorboard
%tensorboard --logdir logs

# æˆ–ä½¿ç”¨ tqdm è¿›åº¦æ¡ï¼ˆå·²é›†æˆåœ¨ train_epoch ä¸­ï¼‰
```

### 4. ä¸‹è½½è®­ç»ƒå¥½çš„æ¨¡å‹

```python
from google.colab import files
files.download('checkpoint.pth')
```

## ğŸ“ æµ‹è¯•å„ä¸ªæ¨¡å—

```python
# æµ‹è¯•æ¨¡å‹å¯¼å…¥
from models import SimpleNN, SimpleCNN, ResNet18, SimpleLSTM
print("âœ… æ¨¡å‹å¯¼å…¥æˆåŠŸ")

# æµ‹è¯•æ•°æ®åŠ è½½
from utils import create_synthetic_dataset
train_loader, test_loader = create_synthetic_dataset()
print("âœ… æ•°æ®åŠ è½½æˆåŠŸ")

# æµ‹è¯•è®­ç»ƒå·¥å…·
from utils import MetricTracker
tracker = MetricTracker()
print("âœ… å·¥å…·å‡½æ•°å¯¼å…¥æˆåŠŸ")

# æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
model = SimpleNN()
x = torch.randn(32, 1, 28, 28)
output = model(x)
print(f"âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
```

## ğŸ¯ å­¦ä¹ è·¯å¾„å»ºè®®

1. **åˆå­¦è€…**ï¼š
   - ä» `SimpleNN` å’Œ `simple_nn.py` å¼€å§‹
   - ä½¿ç”¨åˆæˆæ•°æ®å¿«é€Ÿæµ‹è¯•
   - ç†è§£è®­ç»ƒå¾ªç¯çš„åŸºæœ¬æµç¨‹

2. **è¿›é˜¶è€…**ï¼š
   - å­¦ä¹  `SimpleCNN` å’Œå·ç§¯æ“ä½œ
   - å°è¯• MNIST å’Œ CIFAR-10 æ•°æ®é›†
   - å®éªŒä¸åŒçš„ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡

3. **é«˜çº§ç”¨æˆ·**ï¼š
   - ç ”ç©¶ `ResNet` çš„æ®‹å·®è¿æ¥
   - æ¢ç´¢ LSTM åœ¨åºåˆ—æ•°æ®ä¸Šçš„åº”ç”¨
   - å®ç°è‡ªå®šä¹‰æ¨¡å‹å’Œæ•°æ®å¢å¼º

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æå‡ºé—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ“® è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ Issue æˆ– Email è”ç³»ã€‚

---

**ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼ğŸ‰**

