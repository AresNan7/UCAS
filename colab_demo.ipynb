{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorch å¤šæ–‡ä»¶é¡¹ç›®æ¼”ç¤º\n",
        "\n",
        "è¿™ä¸ª Notebook æ¼”ç¤ºå¦‚ä½•åœ¨ Google Colab ä¸­ä½¿ç”¨å¤šæ–‡ä»¶ PyTorch é¡¹ç›®\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒè®¾ç½®å’Œ Drive æŒ‚è½½\n",
        "\n",
        "### æ­¥éª¤ 1.1: æŒ‚è½½ Google Driveï¼ˆç”¨äºä¿å­˜è®­ç»ƒç»“æœï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# ğŸ—‚ï¸ æŒ‚è½½ Google Drive\n",
        "# ========================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ—‚ï¸  æŒ‚è½½ Google Drive\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# æŒ‚è½½ Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# åˆ›å»ºç»“æœä¿å­˜ç›®å½•\n",
        "RESULTS_DIR = '/content/drive/MyDrive/UCAS_Results'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# åˆ›å»ºæœ¬æ¬¡å®éªŒçš„å­ç›®å½•ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "EXPERIMENT_DIR = os.path.join(RESULTS_DIR, f'experiment_{timestamp}')\n",
        "os.makedirs(EXPERIMENT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\nâœ… Drive å·²æŒ‚è½½\")\n",
        "print(f\"ğŸ“ ç»“æœä¿å­˜ç›®å½•: {RESULTS_DIR}\")\n",
        "print(f\"ğŸ“ æœ¬æ¬¡å®éªŒç›®å½•: {EXPERIMENT_DIR}\")\n",
        "print(f\"â° å®éªŒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# å®šä¹‰ä¿å­˜å‡½æ•°\n",
        "def save_to_drive(content, filename, subdir=''):\n",
        "    \"\"\"\n",
        "    ä¿å­˜å†…å®¹åˆ° Drive\n",
        "    \n",
        "    å‚æ•°:\n",
        "        content: è¦ä¿å­˜çš„å†…å®¹ï¼ˆæ–‡æœ¬ã€æ¨¡å‹ç­‰ï¼‰\n",
        "        filename: æ–‡ä»¶å\n",
        "        subdir: å­ç›®å½•ï¼ˆå¯é€‰ï¼‰\n",
        "    \"\"\"\n",
        "    save_dir = os.path.join(EXPERIMENT_DIR, subdir) if subdir else EXPERIMENT_DIR\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    filepath = os.path.join(save_dir, filename)\n",
        "    \n",
        "    if isinstance(content, str):\n",
        "        # ä¿å­˜æ–‡æœ¬\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "    else:\n",
        "        # ä¿å­˜å…¶ä»–å¯¹è±¡ï¼ˆå¦‚æ¨¡å‹ï¼‰\n",
        "        import torch\n",
        "        torch.save(content, filepath)\n",
        "    \n",
        "    print(f\"âœ… å·²ä¿å­˜: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "print(\"\\nğŸ‰ Drive å‡†å¤‡å®Œæˆï¼\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### æ­¥éª¤ 1.2: å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# ğŸš€ ä» GitHub å…‹éš†é¡¹ç›®ï¼ˆæ¨èæ–¹å¼ï¼‰\n",
        "# ========================================\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“¦ UCAS PyTorch é¡¹ç›®å¯åŠ¨\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# æ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²å­˜åœ¨\n",
        "if os.path.exists('/content/UCAS'):\n",
        "    print(\"\\nâœ… é¡¹ç›®å·²å­˜åœ¨ï¼Œæ‹‰å–æœ€æ–°ä»£ç ...\")\n",
        "    %cd /content/UCAS\n",
        "    !git pull origin main\n",
        "else:\n",
        "    print(\"\\nğŸ“¥ é¦–æ¬¡å…‹éš†é¡¹ç›®...\")\n",
        "    !git clone https://github.com/AresNan7/UCAS.git\n",
        "    %cd UCAS\n",
        "\n",
        "print(f\"\\nğŸ“‚ å½“å‰ç›®å½•: {os.getcwd()}\")\n",
        "\n",
        "# æŸ¥çœ‹é¡¹ç›®ç»“æ„\n",
        "print(\"\\nğŸ“ é¡¹ç›®æ–‡ä»¶:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\nğŸ“ Models ç›®å½•:\")\n",
        "!ls models/\n",
        "\n",
        "print(\"\\nğŸ“ Utils ç›®å½•:\")\n",
        "!ls utils/\n",
        "\n",
        "# å®‰è£…ä¾èµ–\n",
        "print(\"\\nğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
        "!pip install -q torch torchvision torchaudio tqdm numpy matplotlib\n",
        "\n",
        "print(\"\\nğŸ‰ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ£€æŸ¥ç¯å¢ƒå’Œæµ‹è¯•æ¨¡å—å¯¼å…¥\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ” ç¯å¢ƒæ£€æŸ¥\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nPython ç‰ˆæœ¬: {sys.version}\")\n",
        "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
        "    print(f\"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# æµ‹è¯•æ¨¡å—å¯¼å…¥\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“š æµ‹è¯•æ¨¡å—å¯¼å…¥\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    from models import SimpleNN, SimpleCNN, AdvancedCNN, ResNet18, ResNet34, SimpleLSTM, BidirectionalLSTM\n",
        "    print(\"âœ… æ¨¡å‹æ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}\")\n",
        "\n",
        "try:\n",
        "    from utils import train_epoch, validate, test, save_checkpoint, load_checkpoint\n",
        "    from utils import get_mnist_loaders, get_cifar10_loaders, create_synthetic_dataset\n",
        "    from utils import EarlyStopping, MetricTracker\n",
        "    print(\"âœ… å·¥å…·æ¨¡å—å¯¼å…¥æˆåŠŸ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ å·¥å…·å¯¼å…¥å¤±è´¥: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ æ‰€æœ‰æ¨¡å—å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å®éªŒï¼\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å¿«é€Ÿæµ‹è¯•æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•æ‰€æœ‰æ¨¡å‹çš„å‰å‘ä¼ æ’­\n",
        "import torch\n",
        "from models import SimpleNN, SimpleCNN, ResNet18, SimpleLSTM\n",
        "\n",
        "print(\"ğŸ§ª æµ‹è¯•æ‰€æœ‰æ¨¡å‹...\\n\")\n",
        "\n",
        "# 1. SimpleNN (MLP)\n",
        "model = SimpleNN(input_size=784, hidden_sizes=[256, 128], num_classes=10)\n",
        "x = torch.randn(4, 1, 28, 28)\n",
        "output = model(x)\n",
        "print(f\"âœ… SimpleNN - è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}, å‚æ•°: {model.get_num_params():,}\")\n",
        "\n",
        "# 2. SimpleCNN\n",
        "model = SimpleCNN(num_classes=10, in_channels=1)\n",
        "output = model(x)\n",
        "print(f\"âœ… SimpleCNN - è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}, å‚æ•°: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# 3. ResNet18\n",
        "model = ResNet18(num_classes=10, in_channels=3)\n",
        "x = torch.randn(4, 3, 32, 32)\n",
        "output = model(x)\n",
        "print(f\"âœ… ResNet18 - è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}, å‚æ•°: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# 4. SimpleLSTM\n",
        "model = SimpleLSTM(vocab_size=1000, num_classes=5)\n",
        "x = torch.randint(0, 1000, (4, 50))\n",
        "output, _ = model(x)\n",
        "print(f\"âœ… SimpleLSTM - è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}, å‚æ•°: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "print(\"\\nğŸ‰ æ‰€æœ‰æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. å®Œæ•´è®­ç»ƒç¤ºä¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä½¿ç”¨åˆæˆæ•°æ®è¿›è¡Œå¿«é€Ÿè®­ç»ƒæ¼”ç¤ºï¼ˆå«è‡ªåŠ¨ä¿å­˜åŠŸèƒ½ï¼‰\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from models import SimpleNN\n",
        "from utils import create_synthetic_dataset, train_epoch, validate, MetricTracker\n",
        "import sys\n",
        "from io import StringIO\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸƒ å¿«é€Ÿè®­ç»ƒæ¼”ç¤ºï¼ˆä½¿ç”¨åˆæˆæ•°æ®ï¼‰\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# åˆ›å»ºæ—¥å¿—è®°å½•å™¨\n",
        "log_output = []\n",
        "\n",
        "def log_print(msg):\n",
        "    \"\"\"åŒæ—¶æ‰“å°åˆ°å±å¹•å’Œè®°å½•åˆ°æ—¥å¿—\"\"\"\n",
        "    print(msg)\n",
        "    log_output.append(msg)\n",
        "\n",
        "# è®¾ç½®è®¾å¤‡\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "log_print(f\"\\nğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    log_print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# åˆ›å»ºåˆæˆæ•°æ®\n",
        "log_print(\"\\nğŸ“Š åˆ›å»ºæ•°æ®...\")\n",
        "train_loader, test_loader = create_synthetic_dataset(\n",
        "    num_samples=1000, \n",
        "    input_dim=20, \n",
        "    num_classes=5\n",
        ")\n",
        "log_print(f\"âœ… è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}, æµ‹è¯•æ‰¹æ¬¡: {len(test_loader)}\")\n",
        "\n",
        "# åˆ›å»ºæ¨¡å‹\n",
        "log_print(\"\\nğŸ§  åˆ›å»ºæ¨¡å‹...\")\n",
        "model = SimpleNN(input_size=20, hidden_sizes=[64, 32], num_classes=5).to(device)\n",
        "log_print(f\"âœ… æ¨¡å‹å‚æ•°: {model.get_num_params():,}\")\n",
        "\n",
        "# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# è®­ç»ƒ\n",
        "log_print(\"\\nğŸƒ å¼€å§‹è®­ç»ƒ...\")\n",
        "num_epochs = 10\n",
        "tracker = MetricTracker()\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, device, verbose=False\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model, test_loader, criterion, device, verbose=False\n",
        "    )\n",
        "    \n",
        "    tracker.update(train_loss, train_acc, val_loss, val_acc)\n",
        "    \n",
        "    log_msg = (f\"Epoch {epoch+1:2d}/{num_epochs} - \"\n",
        "               f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:5.2f}% | \"\n",
        "               f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:5.2f}%\")\n",
        "    log_print(log_msg)\n",
        "    \n",
        "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc\n",
        "        }\n",
        "        save_to_drive(checkpoint, 'best_model.pth', 'models')\n",
        "\n",
        "# æ‰“å°æ€»ç»“\n",
        "log_print(\"\\n\" + \"=\" * 60)\n",
        "log_print(\"è®­ç»ƒæ€»ç»“\")\n",
        "log_print(\"=\" * 60)\n",
        "log_print(f\"æ€» Epoch æ•°: {len(tracker.train_losses)}\")\n",
        "log_print(f\"æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {tracker.train_accs[-1]:.2f}%\")\n",
        "log_print(f\"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {tracker.val_accs[-1]:.2f}%\")\n",
        "log_print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
        "log_print(\"=\" * 60)\n",
        "\n",
        "# ä¿å­˜è®­ç»ƒæ—¥å¿—åˆ° Drive\n",
        "print(\"\\nğŸ’¾ ä¿å­˜è®­ç»ƒæ—¥å¿—åˆ° Drive...\")\n",
        "log_content = '\\n'.join(log_output)\n",
        "save_to_drive(log_content, 'training_log.txt', 'logs')\n",
        "\n",
        "# ä¿å­˜è®­ç»ƒæŒ‡æ ‡\n",
        "print(\"ğŸ’¾ ä¿å­˜è®­ç»ƒæŒ‡æ ‡...\")\n",
        "metrics_content = f\"\"\"è®­ç»ƒæŒ‡æ ‡æ‘˜è¦\n",
        "{'=' * 50}\n",
        "è®¾å¤‡: {device}\n",
        "æ¨¡å‹: SimpleNN\n",
        "å‚æ•°æ•°é‡: {model.get_num_params():,}\n",
        "\n",
        "è®­ç»ƒé…ç½®:\n",
        "- Epochs: {num_epochs}\n",
        "- å­¦ä¹ ç‡: 0.001\n",
        "- ä¼˜åŒ–å™¨: Adam\n",
        "- æ‰¹æ¬¡å¤§å°: 32\n",
        "\n",
        "è®­ç»ƒç»“æœ:\n",
        "- æœ€ç»ˆè®­ç»ƒæŸå¤±: {tracker.train_losses[-1]:.4f}\n",
        "- æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {tracker.train_accs[-1]:.2f}%\n",
        "- æœ€ç»ˆéªŒè¯æŸå¤±: {tracker.val_losses[-1]:.4f}\n",
        "- æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {tracker.val_accs[-1]:.2f}%\n",
        "- æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\n",
        "\n",
        "è¯¦ç»†æŒ‡æ ‡:\n",
        "Epoch | Train Loss | Train Acc | Val Loss | Val Acc\n",
        "------+------------+-----------+----------+---------\n",
        "\"\"\"\n",
        "for i in range(num_epochs):\n",
        "    metrics_content += f\"{i+1:5d} | {tracker.train_losses[i]:10.4f} | {tracker.train_accs[i]:9.2f}% | {tracker.val_losses[i]:8.4f} | {tracker.val_accs[i]:7.2f}%\\n\"\n",
        "\n",
        "save_to_drive(metrics_content, 'training_metrics.txt', 'logs')\n",
        "\n",
        "print(\"\\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° Google Drive!\")\n",
        "print(f\"ğŸ“ ä¿å­˜ä½ç½®: {EXPERIMENT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. å¯è§†åŒ–è®­ç»ƒç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹çš„æŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿ï¼ˆå¹¶ä¿å­˜åˆ° Driveï¼‰\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "\n",
        "# æŸå¤±æ›²çº¿\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(tracker.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2, marker='o', markersize=4)\n",
        "plt.plot(tracker.val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2, marker='s', markersize=4)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.title('æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# å‡†ç¡®ç‡æ›²çº¿\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(tracker.train_accs, 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2, marker='o', markersize=4)\n",
        "plt.plot(tracker.val_accs, 'r-', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2, marker='s', markersize=4)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.title('å‡†ç¡®ç‡æ›²çº¿', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# ä¿å­˜å›¾è¡¨åˆ° Drive\n",
        "figure_path = os.path.join(EXPERIMENT_DIR, 'figures', 'training_curves.png')\n",
        "os.makedirs(os.path.dirname(figure_path), exist_ok=True)\n",
        "plt.savefig(figure_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"ğŸ’¾ å›¾è¡¨å·²ä¿å­˜åˆ°: {figure_path}\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "best_epoch = tracker.val_accs.index(max(tracker.val_accs)) + 1\n",
        "print(f\"\\nğŸ“Š æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(tracker.val_accs):.2f}% (Epoch {best_epoch})\")\n",
        "\n",
        "# ä¿å­˜è®­ç»ƒæ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰\n",
        "print(\"\\nğŸ’¾ ä¿å­˜è®­ç»ƒæ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰...\")\n",
        "csv_content = \"Epoch,Train_Loss,Train_Acc,Val_Loss,Val_Acc\\n\"\n",
        "for i in range(len(tracker.train_losses)):\n",
        "    csv_content += f\"{i+1},{tracker.train_losses[i]:.6f},{tracker.train_accs[i]:.2f},{tracker.val_losses[i]:.6f},{tracker.val_accs[i]:.2f}\\n\"\n",
        "\n",
        "save_to_drive(csv_content, 'training_data.csv', 'data')\n",
        "\n",
        "print(f\"\\nâœ… è®­ç»ƒå¯è§†åŒ–å®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° Drive\")\n",
        "print(f\"ğŸ“ æŸ¥çœ‹ç»“æœ: {EXPERIMENT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. æ›´å¤šç¤ºä¾‹å’Œè¯´æ˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ’¡ æ›´å¤šä½¿ç”¨ç¤ºä¾‹\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“š å…¶ä»–å¯ç”¨åŠŸèƒ½\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶\n",
        "print(\"\\n1ï¸âƒ£ è¿è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•:\")\n",
        "print(\"   !python test_modules.py\")\n",
        "\n",
        "# 2. ä½¿ç”¨è®­ç»ƒè„šæœ¬\n",
        "print(\"\\n2ï¸âƒ£ ä½¿ç”¨å‘½ä»¤è¡Œè®­ç»ƒè„šæœ¬:\")\n",
        "print(\"   !python train.py --model simple_nn\")\n",
        "print(\"   !python train.py --model cnn\")\n",
        "print(\"   !python train.py --model resnet\")\n",
        "print(\"   !python train.py --model lstm\")\n",
        "\n",
        "# 3. ä½¿ç”¨çœŸå®æ•°æ®é›†\n",
        "print(\"\\n3ï¸âƒ£ ä½¿ç”¨çœŸå®æ•°æ®é›†:\")\n",
        "print(\"   from utils import get_mnist_loaders, get_cifar10_loaders\")\n",
        "print(\"   train_loader, test_loader = get_mnist_loaders(batch_size=128)\")\n",
        "\n",
        "# 4. ä¿å­˜å’ŒåŠ è½½æ¨¡å‹\n",
        "print(\"\\n4ï¸âƒ£ ä¿å­˜å’ŒåŠ è½½æ¨¡å‹:\")\n",
        "print(\"   from utils import save_checkpoint, load_checkpoint\")\n",
        "print(\"   save_checkpoint(model, optimizer, epoch, loss, acc, 'model.pth')\")\n",
        "\n",
        "# 5. æ›´æ–°ä»£ç \n",
        "print(\"\\n5ï¸âƒ£ ä» GitHub æ‹‰å–æœ€æ–°ä»£ç :\")\n",
        "print(\"   %cd /content/UCAS\")\n",
        "print(\"   !git pull origin main\")\n",
        "\n",
        "# 6. æŸ¥çœ‹æ–‡æ¡£\n",
        "print(\"\\n6ï¸âƒ£ æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£:\")\n",
        "print(\"   !cat README_PYTORCH.md\")\n",
        "print(\"   !cat QUICKSTART.md\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. æŸ¥çœ‹ä¿å­˜çš„ç»“æœ\n",
        "\n",
        "### ğŸ“ Drive ä¸­ä¿å­˜çš„æ–‡ä»¶\n",
        "\n",
        "| æ¨¡å‹ | å‚æ•°é‡ | é€‚ç”¨åœºæ™¯ |\n",
        "|------|--------|----------|\n",
        "| SimpleNN | ~569K | MNIST, ç®€å•åˆ†ç±» |\n",
        "| SimpleCNN | ~390K | å›¾åƒåˆ†ç±» |\n",
        "| ResNet18 | ~11M | æ·±åº¦å›¾åƒåˆ†ç±» |\n",
        "| SimpleLSTM | ~1M | æ–‡æœ¬/åºåˆ—åˆ†ç±» |\n",
        "\n",
        "#### ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®\n",
        "\n",
        "1. **è¿è¡Œå®Œæ•´æµ‹è¯•**: `!python test_modules.py`\n",
        "2. **æŸ¥çœ‹è®­ç»ƒè„šæœ¬**: `!python train.py --model simple_nn`\n",
        "3. **å°è¯•çœŸå®æ•°æ®é›†**: MNIST, CIFAR-10\n",
        "4. **é˜…è¯»è¯¦ç»†æ–‡æ¡£**: `!cat README_PYTORCH.md`\n",
        "5. **æŸ¥çœ‹å¿«é€ŸæŒ‡å—**: `!cat QUICKSTART.md`\n",
        "\n",
        "#### ğŸ”„ æ›´æ–°ä»£ç \n",
        "\n",
        "å½“é¡¹ç›®æœ‰æ›´æ–°æ—¶ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤è·å–æœ€æ–°ä»£ç ï¼š\n",
        "\n",
        "```python\n",
        "%cd /content/UCAS\n",
        "!git pull origin main\n",
        "```\n",
        "\n",
        "#### ğŸ“– ç›¸å…³èµ„æº\n",
        "\n",
        "- **GitHub ä»“åº“**: https://github.com/AresNan7/UCAS\n",
        "- **å®Œæ•´æ–‡æ¡£**: README_PYTORCH.md\n",
        "- **å¿«é€Ÿå…¥é—¨**: QUICKSTART.md\n",
        "- **é¡¹ç›®æ€»è§ˆ**: PROJECT_OVERVIEW.md\n",
        "\n",
        "---\n",
        "\n",
        "**ç¥ä½ å®éªŒæ„‰å¿«ï¼** ğŸ“ğŸš€\n",
        "\n",
        "å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ–‡æ¡£æˆ–åœ¨ GitHub ä¸Šæ Issueã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ—å‡º Drive ä¸­ä¿å­˜çš„æ‰€æœ‰æ–‡ä»¶\n",
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"ğŸ“ æœ¬æ¬¡å®éªŒä¿å­˜çš„æ–‡ä»¶\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nå®éªŒç›®å½•: {EXPERIMENT_DIR}\\n\")\n",
        "\n",
        "def list_files_recursive(directory, prefix=''):\n",
        "    \"\"\"é€’å½’åˆ—å‡ºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶\"\"\"\n",
        "    items = []\n",
        "    try:\n",
        "        for item in sorted(os.listdir(directory)):\n",
        "            item_path = os.path.join(directory, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                items.append(f\"{prefix}ğŸ“ {item}/\")\n",
        "                items.extend(list_files_recursive(item_path, prefix + '  '))\n",
        "            else:\n",
        "                size = os.path.getsize(item_path)\n",
        "                size_str = f\"{size/1024:.1f}KB\" if size < 1024*1024 else f\"{size/1024/1024:.1f}MB\"\n",
        "                items.append(f\"{prefix}ğŸ“„ {item} ({size_str})\")\n",
        "    except Exception as e:\n",
        "        items.append(f\"{prefix}âŒ é”™è¯¯: {e}\")\n",
        "    return items\n",
        "\n",
        "# æ˜¾ç¤ºæ–‡ä»¶æ ‘\n",
        "file_list = list_files_recursive(EXPERIMENT_DIR)\n",
        "for item in file_list:\n",
        "    print(item)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ’¡ æç¤º:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. åœ¨ Google Drive ä¸­æ‰“å¼€ä»¥ä¸‹è·¯å¾„æŸ¥çœ‹æ–‡ä»¶:\")\n",
        "print(f\"   {RESULTS_DIR}\")\n",
        "print(\"\\n2. ä¸‹è½½ç‰¹å®šæ–‡ä»¶:\")\n",
        "print(\"   from google.colab import files\")\n",
        "print(f\"   files.download('{EXPERIMENT_DIR}/models/best_model.pth')\")\n",
        "print(\"\\n3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—:\")\n",
        "print(f\"   !cat '{EXPERIMENT_DIR}/logs/training_log.txt'\")\n",
        "print(\"\\n4. æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡:\")\n",
        "print(f\"   !cat '{EXPERIMENT_DIR}/logs/training_metrics.txt'\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. æ€»ç»“\n",
        "\n",
        "### ğŸ‰ å®Œæˆï¼\n",
        "\n",
        "è¿™ä¸ª Notebook æ¼”ç¤ºäº†å¦‚ä½•åœ¨ Google Colab ä¸­ä½¿ç”¨å¤šæ–‡ä»¶ PyTorch é¡¹ç›®ï¼š\n",
        "\n",
        "#### âœ… æœ¬ Notebook æ¶µç›–å†…å®¹\n",
        "\n",
        "1. **æŒ‚è½½ Google Drive** - è‡ªåŠ¨ä¿å­˜è®­ç»ƒç»“æœåˆ°äº‘ç«¯\n",
        "2. **ä» GitHub å…‹éš†é¡¹ç›®** - æ™ºèƒ½æ£€æµ‹ï¼Œè‡ªåŠ¨æ›´æ–°ä»£ç \n",
        "3. **ç¯å¢ƒæ£€æŸ¥å’Œæ¨¡å—æµ‹è¯•** - éªŒè¯æ‰€æœ‰ä¾èµ–å’Œæ¨¡å—\n",
        "4. **æ¨¡å‹æµ‹è¯•** - æµ‹è¯• SimpleNN, CNN, ResNet, LSTM\n",
        "5. **å®Œæ•´è®­ç»ƒæµç¨‹** - ä»æ•°æ®åŠ è½½åˆ°æ¨¡å‹è®­ç»ƒ\n",
        "6. **å®æ—¶æ—¥å¿—è®°å½•** - è®°å½•æ‰€æœ‰è®­ç»ƒè¾“å‡º\n",
        "7. **è‡ªåŠ¨ä¿å­˜ç»“æœ** - æ¨¡å‹ã€æ—¥å¿—ã€å›¾è¡¨ã€æ•°æ®å…¨éƒ¨ä¿å­˜åˆ° Drive\n",
        "\n",
        "#### ğŸ’¾ è‡ªåŠ¨ä¿å­˜çš„æ–‡ä»¶\n",
        "\n",
        "è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»¥ä¸‹æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åˆ° Google Driveï¼š\n",
        "\n",
        "```\n",
        "UCAS_Results/\n",
        "â””â”€â”€ experiment_YYYYMMDD_HHMMSS/\n",
        "    â”œâ”€â”€ models/\n",
        "    â”‚   â””â”€â”€ best_model.pth          # æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹\n",
        "    â”œâ”€â”€ logs/\n",
        "    â”‚   â”œâ”€â”€ training_log.txt        # å®Œæ•´è®­ç»ƒæ—¥å¿—\n",
        "    â”‚   â””â”€â”€ training_metrics.txt    # è®­ç»ƒæŒ‡æ ‡æ‘˜è¦\n",
        "    â”œâ”€â”€ figures/\n",
        "    â”‚   â””â”€â”€ training_curves.png     # è®­ç»ƒæ›²çº¿å›¾\n",
        "    â””â”€â”€ data/\n",
        "        â””â”€â”€ training_data.csv       # è®­ç»ƒæ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰\n",
        "```\n",
        "\n",
        "#### ğŸ“š é¡¹ç›®åŒ…å«çš„æ¨¡å‹\n",
        "\n",
        "| æ¨¡å‹ | å‚æ•°é‡ | é€‚ç”¨åœºæ™¯ |\n",
        "|------|--------|----------|\n",
        "| SimpleNN | ~569K | MNIST, ç®€å•åˆ†ç±» |\n",
        "| SimpleCNN | ~390K | å›¾åƒåˆ†ç±» |\n",
        "| ResNet18 | ~11M | æ·±åº¦å›¾åƒåˆ†ç±» |\n",
        "| SimpleLSTM | ~1M | æ–‡æœ¬/åºåˆ—åˆ†ç±» |\n",
        "\n",
        "#### ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®\n",
        "\n",
        "1. **è¿è¡Œå®Œæ•´æµ‹è¯•**: `!python test_modules.py`\n",
        "2. **æŸ¥çœ‹è®­ç»ƒè„šæœ¬**: `!python train.py --model simple_nn`\n",
        "3. **å°è¯•çœŸå®æ•°æ®é›†**: MNIST, CIFAR-10\n",
        "4. **é˜…è¯»è¯¦ç»†æ–‡æ¡£**: `!cat README_PYTORCH.md`\n",
        "5. **æŸ¥çœ‹ä¿å­˜çš„ç»“æœ**: æ‰“å¼€ Google Drive æŸ¥çœ‹è®­ç»ƒç»“æœ\n",
        "\n",
        "#### ğŸ”„ æ›´æ–°ä»£ç \n",
        "\n",
        "å½“é¡¹ç›®æœ‰æ›´æ–°æ—¶ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤è·å–æœ€æ–°ä»£ç ï¼š\n",
        "\n",
        "```python\n",
        "%cd /content/UCAS\n",
        "!git pull origin main\n",
        "```\n",
        "\n",
        "#### ğŸ“– ç›¸å…³èµ„æº\n",
        "\n",
        "- **GitHub ä»“åº“**: https://github.com/AresNan7/UCAS\n",
        "- **å®Œæ•´æ–‡æ¡£**: README_PYTORCH.md\n",
        "- **å¿«é€Ÿå…¥é—¨**: QUICKSTART.md\n",
        "- **é¡¹ç›®æ€»è§ˆ**: PROJECT_OVERVIEW.md\n",
        "\n",
        "---\n",
        "\n",
        "**ç¥ä½ å®éªŒæ„‰å¿«ï¼** ğŸ“ğŸš€\n",
        "\n",
        "æ‰€æœ‰è®­ç»ƒç»“æœéƒ½å·²ä¿å­˜åˆ° Google Driveï¼Œæ–­å¼€ Colab ä¹Ÿä¸ä¼šä¸¢å¤±ï¼\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
